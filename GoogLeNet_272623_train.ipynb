{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "C:\\ProgramData\\Anaconda3\\python.exe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers import Conv2D,MaxPool2D,MaxPooling2D,GlobalAveragePooling2D,AveragePooling2D,Input, concatenate\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "import itertools\n",
    "import pickle\n",
    "from keras.models import Model,load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(k1_n):\n",
    "    if k1_n == 2:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA1_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA1_lt2.dat'\n",
    "    if k1_n == 3:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt2.dat'\n",
    "    if k1_n == 4:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K1-272623_peptide_nm1_RAAA1_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K1-272623_peptide_nm1_RAAA1_lt2.dat'\n",
    "    if k1_n == 5:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K1-272623_peptide_nm1_RAAA2_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K1-272623_peptide_nm1_RAAA2_lt2.dat'\n",
    "    if k1_n == 6:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-balance-272623_peptide_nm1_RAAA1_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-balance-272623_peptide_nm1_RAAA1_lt2.dat'\n",
    "    if k1_n == 7:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-balance-272623_peptide_nm1_RAAA2_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-balance-272623_peptide_nm1_RAAA2_lt2.dat'\n",
    "    if k1_n == 8:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K3-272623_peptide_nm1_RAAA1_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K3-272623_peptide_nm1_RAAA1_lt2.dat'\n",
    "    if k1_n == 9:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K3-272623_peptide_nm1_RAAA2_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K3-272623_peptide_nm1_RAAA2_lt2.dat'\n",
    "    if k1_n == 10:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K5-272623_peptide_nm1_RAAA1_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K5-272623_peptide_nm1_RAAA1_lt2.dat'\n",
    "    if k1_n == 11:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K5-272623_peptide_nm1_RAAA2_lt2'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K5-272623_peptide_nm1_RAAA2_lt2.dat'\n",
    "    \n",
    "        \n",
    "    if k1_n == 12:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3.dat'\n",
    "    if k1_n == 13:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA3_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA3_lt3.dat'\n",
    "    if k1_n == 14:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K1-272623_peptide_nm1_RAAA2_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K1-272623_peptide_nm1_RAAA2_lt3.dat'\n",
    "    if k1_n == 15:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K1-272623_peptide_nm1_RAAA3_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K1-272623_peptide_nm1_RAAA3_lt3.dat'\n",
    "    if k1_n == 16:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-balance-272623_peptide_nm1_RAAA2_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-balance-272623_peptide_nm1_RAAA2_lt3.dat'\n",
    "    if k1_n == 17:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-balance-272623_peptide_nm1_RAAA3_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-balance-272623_peptide_nm1_RAAA3_lt3.dat'\n",
    "    if k1_n == 18:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K3-272623_peptide_nm1_RAAA2_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K3-272623_peptide_nm1_RAAA2_lt3.dat'\n",
    "    if k1_n == 19:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K3-272623_peptide_nm1_RAAA3_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K3-272623_peptide_nm1_RAAA3_lt3.dat'\n",
    "    if k1_n == 20:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K5-272623_peptide_nm1_RAAA2_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K5-272623_peptide_nm1_RAAA2_lt3.dat'\n",
    "    if k1_n == 21:\n",
    "        ver = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K5-272623_peptide_nm1_RAAA3_lt3'\n",
    "        data = '272623-10.5-11.0-train-Valid-cdhit60-Ushuffle-seed0-K5-272623_peptide_nm1_RAAA3_lt3.dat'\n",
    "    \n",
    "    data_path = './272623/data/'\n",
    "    train_path = data_path+data\n",
    "    return train_path,ver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_data(train_path):\n",
    "    y_train= list()\n",
    "    X_train= list()\n",
    "    f = open(train_path,'r')\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    data_train = s.split(\"\\n\")\n",
    "    data_train.pop()\n",
    "    random.shuffle(data_train)\n",
    "    #print(data_train[0])\n",
    "    for i in data_train:\n",
    "        data_t = i.split(\" \",1)\n",
    "        y_train.append(data_t[0])\n",
    "        X_train.append(data_t[1])\n",
    "        #print(data_t[0])\n",
    "        #print(data_t[1])\n",
    "    data_x_train = list()\n",
    "    for i in range(0,len(X_train)):\n",
    "        data_t2 = X_train[i].split(\" \")\n",
    "        data_t2.pop()\n",
    "        #print(len(data_t2))\n",
    "        data_x_train.append(np.zeros( len(data_t2) ))\n",
    "        for i_2 in data_t2:\n",
    "            temp = i_2.split(\":\")\n",
    "            temp[0] = int(temp[0])-1\n",
    "            temp[1] = float(temp[1])\n",
    "            data_x_train[i][temp[0]] = temp[1]\n",
    "            #print(type(temp[0]) )\n",
    "            #print(type(temp[1]) )\n",
    "    X_train = np.array(data_x_train)\n",
    "    y_train_label = np.array(y_train)\n",
    "        \n",
    "    #X_test = np.array(data_x_test)\n",
    "    #y_test_label = np.array(y_test)\n",
    "    \n",
    "    #print(X_train.shape)\n",
    "    #print(y_train_label.shape)\n",
    "    #print(X_test.shape)\n",
    "    #print(y_test_label.shape)\n",
    "    \n",
    "    len_type = int( (len(data_x_train[0])/2) ** 0.5 ) \n",
    "    \n",
    "    X_train = np.reshape(X_train, [-1,len_type,len_type,2])\n",
    "    #X_test = np.reshape(X_test, [-1,2,len_type,len_type])\n",
    "    #X_test = np.swapaxes(X_test,1,3)\n",
    "    y_train_onehot = to_categorical(y_train_label)\n",
    "    #y_test_onehot = to_categorical(y_test_label)\n",
    "    print(X_train.shape)\n",
    "    print(y_train_onehot.shape)\n",
    "    #print(X_test.shape)\n",
    "    #print(y_test_onehot.shape)\n",
    "    return len_type,X_train,y_train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_data_lt3(train_path):\n",
    "    y_train= list()\n",
    "    X_train= list()\n",
    "    f = open(train_path,'r')\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    data_train = s.split(\"\\n\")\n",
    "    data_train.pop()\n",
    "    random.shuffle(data_train)\n",
    "    #print(data_train[0])\n",
    "    for i in data_train:\n",
    "        data_t = i.split(\" \",1)\n",
    "        y_train.append(data_t[0])\n",
    "        X_train.append(data_t[1])\n",
    "        #print(data_t[0])\n",
    "        #print(data_t[1])\n",
    "    data_x_train = list()\n",
    "    for i in range(0,len(X_train)):\n",
    "        data_t2 = X_train[i].split(\" \")\n",
    "        data_t2.pop()\n",
    "        #print(len(data_t2))\n",
    "        data_x_train.append(np.zeros( len(data_t2) ))\n",
    "        for i_2 in data_t2:\n",
    "            temp = i_2.split(\":\")\n",
    "            temp[0] = int(temp[0])-1\n",
    "            temp[1] = float(temp[1])\n",
    "            data_x_train[i][temp[0]] = temp[1]\n",
    "            #print(type(temp[0]) )\n",
    "            #print(type(temp[1]) )\n",
    "    X_train = np.array(data_x_train)\n",
    "    y_train_label = np.array(y_train)\n",
    "        \n",
    "    #X_test = np.array(data_x_test)\n",
    "    #y_test_label = np.array(y_test)\n",
    "    \n",
    "    #print(X_train.shape)\n",
    "    #print(y_train_label.shape)\n",
    "    #print(X_test.shape)\n",
    "    #print(y_test_label.shape)\n",
    "    \n",
    "    len_type = int( pow((len(data_x_train[0])/2),1/3) +1) \n",
    "    print(len_type)\n",
    "    X_train = np.reshape(X_train, [-1,len_type,len_type,len_type*2])\n",
    "    #X_test = np.reshape(X_test, [-1,2,len_type,len_type])\n",
    "    #X_test = np.swapaxes(X_test,1,3)\n",
    "    y_train_onehot = to_categorical(y_train_label)\n",
    "    #y_test_onehot = to_categorical(y_test_label)\n",
    "    print(X_train.shape)\n",
    "    print(y_train_onehot.shape)\n",
    "    #print(X_test.shape)\n",
    "    #print(y_test_onehot.shape)\n",
    "    return len_type,X_train,y_train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='same',strides=(1,1),name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=3,name=bn_name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception(x,nb_filter_para):\n",
    "    (branch1,branch2,branch3,branch4)= nb_filter_para\n",
    "    branch1x1 = Conv2D(branch1[0],(1,1), padding='same',strides=(1,1),name=None)(x)\n",
    "\n",
    "    branch3x3 = Conv2D(branch2[0],(1,1), padding='same',strides=(1,1),name=None)(x)\n",
    "    branch3x3 = Conv2D(branch2[1],(3,3), padding='same',strides=(1,1),name=None)(branch3x3)\n",
    "\n",
    "    branch5x5 = Conv2D(branch3[0],(1,1), padding='same',strides=(1,1),name=None)(x)\n",
    "    branch5x5 = Conv2D(branch3[1],(1,1), padding='same',strides=(1,1),name=None)(branch5x5)\n",
    "\n",
    "    branchpool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same')(x)\n",
    "    branchpool = Conv2D(branch4[0],(1,1),padding='same',strides=(1,1),name=None)(branchpool)\n",
    "\n",
    "    x = concatenate([branch1x1,branch3x3,branch5x5,branchpool],axis=3)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionV1(width, height, depth, classes):\n",
    "    \n",
    "    inpt = Input(shape=(width,height,depth))\n",
    "\n",
    "    x = Conv2d_BN(inpt,64,(7,7),strides=(2,2),padding='same')\n",
    "    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n",
    "    x = Conv2d_BN(x,192,(3,3),strides=(1,1),padding='same')\n",
    "    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n",
    "\n",
    "    x = Inception(x,[(64,),(96,128),(16,32),(32,)]) #Inception 3a 28x28x256\n",
    "    x = Inception(x,[(128,),(128,192),(32,96),(64,)]) #Inception 3b 28x28x480\n",
    "    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x) #14x14x480\n",
    "\n",
    "    x = Inception(x,[(192,),(96,208),(16,48),(64,)]) #Inception 4a 14x14x512\n",
    "    x = Inception(x,[(160,),(112,224),(24,64),(64,)]) #Inception 4a 14x14x512\n",
    "    x = Inception(x,[(128,),(128,256),(24,64),(64,)]) #Inception 4a 14x14x512\n",
    "    x = Inception(x,[(112,),(144,288),(32,64),(64,)]) #Inception 4a 14x14x528\n",
    "    x = Inception(x,[(256,),(160,320),(32,128),(128,)]) #Inception 4a 14x14x832\n",
    "    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x) #7x7x832\n",
    "\n",
    "    x = Inception(x,[(256,),(160,320),(32,128),(128,)]) #Inception 5a 7x7x832\n",
    "    x = Inception(x,[(384,),(192,384),(48,128),(128,)]) #Inception 5b 7x7x1024\n",
    "\n",
    "    #Using AveragePooling replace flatten\n",
    "    x = AveragePooling2D(pool_size=(7,7),strides=(7,7),padding='same')(x)\n",
    "    x =Flatten()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1000,activation='relu')(x)\n",
    "    x = Dense(classes,activation='softmax')(x)\n",
    "    \n",
    "    model=Model(input=inpt,output=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9693, 20, 20, 2)\n",
      "(9693, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8723 samples, validate on 970 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-18d7b39373f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         )\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 1000\n",
    "num_classes = 2\n",
    "weight_decay = 1e-5\n",
    "patience = [20,40,60,80,100]\n",
    "for p in patience:\n",
    "    for k in range(2,8):\n",
    "        train_path,ver = get_data(k)\n",
    "        len_type,X_train,y_train_onehot = deal_data(train_path)\n",
    "        model_path = './model/GoogLeNet/'+ver+'p='+str(p)+'.hdf5'\n",
    "        \n",
    "        InceptionV1_model = InceptionV1(len_type,len_type,2,2)\n",
    "        #InceptionV1_model.summary()\n",
    "        InceptionV1_model.compile(optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08),loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "        es=EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=p,\n",
    "            verbose=0,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        mc=ModelCheckpoint(\n",
    "            model_path,\n",
    "            monitor='val_accuracy',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='max',\n",
    "            period=1\n",
    "        )\n",
    "        \n",
    "    \n",
    "        history = InceptionV1_model.fit(\n",
    "            X_train,\n",
    "            y_train_onehot,\n",
    "            batch_size=batch_size,\n",
    "            epochs = epochs,\n",
    "            callbacks=[es,mc],\n",
    "            validation_split = 0.1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        with open(model_path+'_train_log.txt',\"w\") as f:\n",
    "            f.write('Patience:' + str(p) + '\\n')\n",
    "            f.write('Train accuracy:' + str(max(history.history['accuracy']) ) + '\\n')\n",
    "            f.write('Val accuracy:' + str(max(history.history['val_accuracy']) ) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "(9693, 13, 13, 26)\n",
      "(9693, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68763, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68763\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68763\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68763\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68763\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.68763 to 0.68866, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.68866 to 0.80515, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.80515\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80515\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.80515 to 0.83402, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83402 to 0.84227, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84227\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84227\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84227\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84227\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84227\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84227\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84227\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84227 to 0.84742, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84742\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84742\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84742\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84742\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84742\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84742\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84742\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.84742 to 0.84948, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84948\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84948\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84948\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84948\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84948\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.84948 to 0.85258, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85258\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85258\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85258\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85258\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85258\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85258\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.85258 to 0.85361, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.85361 to 0.86186, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA2_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.86186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.86186\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.86186\n",
      "11\n",
      "(9693, 11, 11, 22)\n",
      "(9693, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68041, saving model to ./model/GoogLeNet/272623-10.5-11.0-train-Valid-cdhit60-LeftRight-seed0-272623_peptide_nm1_RAAA3_lt3p=100.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68041\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-63980fdd61bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         )\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_train_log.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 1000\n",
    "num_classes = 2\n",
    "weight_decay = 1e-5\n",
    "patience = [100]\n",
    "for p in patience:\n",
    "    for k in range(8,14):\n",
    "        train_path,ver = get_data(k)\n",
    "        len_type,X_train,y_train_onehot = deal_data_lt3(train_path)\n",
    "        model_path = './model/GoogLeNet/'+ver+'p='+str(p)+'.hdf5'\n",
    "        \n",
    "        InceptionV1_model = InceptionV1(len_type,len_type,len_type*2,2)\n",
    "        #InceptionV1_model.summary()\n",
    "        InceptionV1_model.compile(optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08),loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "        es=EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=p,\n",
    "            verbose=0,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        mc=ModelCheckpoint(\n",
    "            model_path,\n",
    "            monitor='val_accuracy',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='max',\n",
    "            period=1\n",
    "        )\n",
    "        \n",
    "    \n",
    "        history = InceptionV1_model.fit(\n",
    "            X_train,\n",
    "            y_train_onehot,\n",
    "            batch_size=batch_size,\n",
    "            epochs = epochs,\n",
    "            callbacks=[es,mc],\n",
    "            validation_split = 0.1,\n",
    "            verbose=0\n",
    "        )\n",
    "        with open(model_path+'_train_log.txt',\"w\") as f:\n",
    "            f.write('Patience:' + str(p) + '\\n')\n",
    "            f.write('Train accuracy:' + str(max(history.history['accuracy']) ) + '\\n')\n",
    "            f.write('Val accuracy:' + str(max(history.history['val_accuracy']) ) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
